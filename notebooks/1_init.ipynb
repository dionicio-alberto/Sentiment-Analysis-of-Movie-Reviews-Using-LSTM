{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Movie Reviews Using LSTM\n",
    "\n",
    "We will turn our attention to recurrent neural networks (RNNs), in particular, to long short-term memory (LSTM) networks and how they can be used in sequencial problems, such as Natural Lenguage Processing (NPL). We will develop and train a LSTM network to predict the sentiment of movie reviews on IMDb\n",
    "\n",
    "\n",
    "-----\n",
    "## Sequential problems in machine learning\n",
    "\n",
    "Sequential problems are a class of problems in machine learning in which the order of the features presented to the model is important for making predictions. These are commonly encountered in the following scenarios:\n",
    "\n",
    "- NPL: sentiment analysis, lenguage translation, text prediction\n",
    "- Time series predictions\n",
    "\n",
    "Many NLP problems are sequential problems, because the languages that we speak are sequential in nature, and the sequence conveys context and other subtle nuances.\n",
    "\n",
    "Sequential problems also occur naturally in time series proble,s. Time series problems are common in stock markets.\n",
    "\n",
    "-----\n",
    "## NLP and sentiment analsys\n",
    "\n",
    "NLP is a subfiled in artificial intelligence that is concerned with the interaction of computers and human lenguages. \n",
    "\n",
    "With the proliferation of deep learning and neural networks in the image classification domian, scientists began to wonder whether the powers of neural networks could be applied to NPL. The ability of AI assistants, such as Siri and Alexa, to understand multiple languages spoken in different accents was the result of deep learning and LSTM networks.\n",
    "\n",
    "Sentiment analysis is also an area of NLP that benefited from the resurgence of deep learning. It is defined as the prediction of the positivity of a text. Most sentiment analysis problems are classification problems (psotive, neutral or negative) and not regression problems. \n",
    "\n",
    "-----\n",
    "## Why sentiment analysis is difficult\n",
    "\n",
    "Due to the presence of subtle nuances in human lenguage. The same word can often covey a differnet meaning depending on the context.\n",
    "\n",
    "Another reason sentiment analysis is difficult is because of sarcasm\n",
    "\n",
    "-----\n",
    "## RNN (Recurrent nerual networks)\n",
    "\n",
    "An RNN has high-level architecture, as shown in the following diagram\n",
    "\n",
    "![diagram](https://i.imgur.com/mIUxURI.png)\n",
    "\n",
    "We can see that an RNN is a multi-layered neural networl. We can break up the raw input, splitting it into time steps. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## What's inside an RNN?\n",
    "\n",
    "The following diagram depicts the mathematical function inside each layer of an RNN:\n",
    "\n",
    "![diagram2](https://i.imgur.com/SjCsxjw.png)\n",
    "\n",
    "The mathematical function of an RNN is simple. Each layer $t$ within an RNN has two inputs\n",
    "\n",
    "- The input from the time step $t$\n",
    "- The gidden state passed from the previus layer $t-1$\n",
    "\n",
    "Each layer in RNN simply sums up the two inputs and applies a tanh($x$) function to the sum. It then outputs the result, to be passed as a hidden state to the next layer. More formally, the output hidden state of layer $t$ is this \n",
    "\n",
    "$$ s_t = \\tanh (s_{t-1}+x_t) $$\n",
    "\n",
    "The tanh function is a good choice as a non-linear transformation of the combinations of the current input and the previus hidden state, becaus it ensure that the weights don't diverge too rapidly and is easily differentiable.\n",
    "\n",
    "Finally, to get the final output from the last layer in the RNN we apply a sigmoid function.\n",
    "\n",
    "We can see that if we stack these layers together, the final output from an RNN depends on the non-linear combination of the inputs at different time steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
